---
title: aws-bedrock
subtitle: AWS Bedrock provider for BAML
---


The `aws-bedrock` provider supports all text-output models available via the
[`Converse` API](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html).

Example:

```baml BAML
client<llm> MyClient {
  provider aws-bedrock
  options {
    inference_configuration {
      max_tokens 100
    }
    // model_id "mistral.mistral-7b-instruct-v0:2"
    // model "anthropic.claude-3-5-sonnet-20240620-v1:0"
    // model_id "anthropic.claude-3-haiku-20240307-v1:0"
    model "meta.llama3-8b-instruct-v1:0"
  }
}
```

## Authorization

We use the AWS SDK under the hood, which will respect [all authentication
mechanisms supported by the
SDK](https://docs.rs/aws-config/latest/aws_config/index.html), including:

- Environment variables (`AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`)
- AWS SSO (Single Sign-On) credentials from `~/.aws/config`
- IAM Role credentials for services running in AWS (EC2, ECS, Lambda)
- AWS credentials file (`~/.aws/credentials`)
- AWS config file profiles (`~/.aws/config`)

For SSO users, ensure you've run `aws sso login` with your profile first. Then you can use the profile in your BAML configuration:

```baml
client<llm> MyClient {
  provider aws-bedrock
  options {
    profile "my-sso-profile"  // Profile name from ~/.aws/config
    model "anthropic.claude-3-sonnet-20240229-v1:0"
  }
}
```

You can also specify credentials directly in your BAML configuration (not recommended for production):

```baml
client<llm> MyClient {
  provider aws-bedrock
  options {
    access_key_id env.AWS_ACCESS_KEY_ID
    secret_access_key env.AWS_SECRET_ACCESS_KEY
    region "us-east-1"
    model "anthropic.claude-3-sonnet-20240229-v1:0"
  }
}
```

## Playground setup
Add these three environment variables to your extension variables to use the AWS Bedrock provider in the playground.

- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`
- `AWS_REGION` - like `us-east-1`
<img src="/assets/vscode/bedrock-playground.png" width="400px" />

## Non-forwarded options

<ParamField
  path="default_role"
  type="string"
>
  The default role for any prompts that don't specify a role. **Default: `system`**

  We don't have any checks for this field, you can pass any string you wish.
</ParamField>

<Markdown src="/snippets/role-selection.mdx" />

<Markdown src="/snippets/allowed-role-metadata-basic.mdx" />
<Markdown src="/snippets/supports-streaming.mdx" />

<ParamField
  path="region"
  type="string"
>
  The AWS region to use. **Default: `AWS_REGION` environment variable**

  We don't have any checks for this field, you can pass any string you wish.
</ParamField>

<ParamField
  path="access_key_id"
  type="string"
>
  The AWS access key ID to use. **Default: `AWS_ACCESS_KEY_ID` environment variable**
</ParamField>

<ParamField
  path="secret_access_key"
  type="string"
>
  The AWS secret access key to use. **Default: `AWS_SECRET_ACCESS_KEY` environment variable**
</ParamField>

<ParamField
  path="session_token"
  type="string"
>
  A temporary session token for AWS authentication, typically used with temporary security credentials. **Default: `AWS_SESSION_TOKEN` environment variable**

  This is commonly used when assuming IAM roles or using temporary credentials from AWS STS (Security Token Service).
</ParamField>

<ParamField
  path="profile"
  type="string"
>
  The AWS profile to use from your AWS credentials file (typically `~/.aws/credentials`). This allows you to specify different sets of credentials for different AWS accounts or roles. **Default: `AWS_PROFILE` environment variable**

  Example:
  ```baml
  client<llm> MyClient {
    provider aws-bedrock
    options {
      profile "my-aws-profile"
      model "anthropic.claude-3-sonnet-20240229-v1:0"
    }
  }
  ```
</ParamField>

<Markdown src="/snippets/finish-reason.mdx" />

## Forwarded options

<ParamField
   path="messages"
   type="DO NOT USE"
>
  BAML will auto construct this field for you from the prompt
</ParamField>

<ParamField
  path="model (or model_id)"
  type="string"
>
  The model to use.

| Model           | Description                    |
| --------------- | ------------------------------ |
| `anthropic.claude-3-5-sonnet-20240620-v1:0` | Smartest              |
| `anthropic.claude-3-haiku-20240307-v1:0`  | Fastest + Cheapest    |
| `meta.llama3-8b-instruct-v1:0`            |                       |
| `meta.llama3-70b-instruct-v1:0`           |                       |
| `mistral.mistral-7b-instruct-v0:2`        |                       |
| `mistral.mixtral-8x7b-instruct-v0:1`      |                       |

Run `aws bedrock list-foundation-models | jq '.modelSummaries.[].modelId` to get
a list of available foundation models; you can also use any custom models you've
deployed.

Note that to use any of these models you'll need to [request model access].

[request model access]: https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html

</ParamField>

<ParamField path="inference_configuration" type="object">
Additional inference configuration to send with the request; see [AWS Bedrock
documentation](https://docs.rs/aws-sdk-bedrockruntime/latest/aws_sdk_bedrockruntime/types/struct.InferenceConfiguration.html).

Example:

```baml BAML
client<llm> MyClient {
  provider aws-bedrock
  options {
    inference_configuration {
      max_tokens 1000
      temperature 1.0
      top_p 0.8
    }
  }
}
```

</ParamField>
